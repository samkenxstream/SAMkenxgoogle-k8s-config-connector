diff --git a/third_party/github.com/hashicorp/terraform-provider-google-beta/google-beta/resource_dataflow_job.go b/third_party/github.com/hashicorp/terraform-provider-google-beta/google-beta/resource_dataflow_job.go
index a024b8fa8..cec940a8f 100644
--- a/third_party/github.com/hashicorp/terraform-provider-google-beta/google-beta/resource_dataflow_job.go
+++ b/third_party/github.com/hashicorp/terraform-provider-google-beta/google-beta/resource_dataflow_job.go
@@ -1,13 +1,13 @@
 package google
 
 import (
-	"context"
+	"errors"
 	"fmt"
 	"log"
+	"regexp"
 	"strings"
 	"time"
 
-	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/customdiff"
 	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/schema"
 	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/validation"
 
@@ -31,6 +31,11 @@ var dataflowTerminalStatesMap = map[string]struct{}{
 	"JOB_STATE_DRAINED":   {},
 }
 
+var subnetRelativeLinkRegex = regexp.MustCompile(`projects/(?P<project>[^/]+)/regions/(?P<region>[^/]+)/subnetworks/(?P<name>[^/]+)$`)
+var subnetRegionalLinkRegex = regexp.MustCompile(`regions/(?P<region>[^/]+)/subnetworks/(?P<name>[^/]+)$`)
+
+var activeJobNotFoundError = errors.New("active job not found")
+
 func resourceDataflowJobLabelDiffSuppress(k, old, new string, d *schema.ResourceData) bool {
 	// Example Diff: "labels.goog-dataflow-provided-template-version": "word_count" => ""
 	if strings.HasPrefix(k, resourceDataflowJobGoogleProvidedLabelPrefix) && new == "" {
@@ -47,6 +52,24 @@ func resourceDataflowJobLabelDiffSuppress(k, old, new string, d *schema.Resource
 	return false
 }
 
+func resourceDataflowJobSubnetworkDiffSuppress(k, old, new string, d *schema.ResourceData) bool {
+	// 'old' should always be a self_link ("https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/subnetworks/{subnetwork_name}")
+	// since 'subnetwork' is converted to a self_link when read from the API.
+	// However, just in case, check if 'old' is not in the expected format.
+	if !subnetRelativeLinkRegex.MatchString(old) {
+		return false
+	}
+	if subnetRegionalLinkRegex.MatchString(new) && !subnetRelativeLinkRegex.MatchString(new) {
+		// 'new' ends with a regional link ("regions/{region}/subnetworks/{subnetwork_name}"),
+		// but not a relative link ("projects/{project}/regions/{region}/subnetworks/{subnetwork_name}")
+		oldMatch := subnetRegionalLinkRegex.FindString(old)
+		newMatch := subnetRegionalLinkRegex.FindString(new)
+		return oldMatch == newMatch
+	}
+	return compareSelfLinkOrResourceName(k, old, new, d)
+}
+
+
 func ResourceDataflowJob() *schema.Resource {
 	return &schema.Resource{
 		Create: resourceDataflowJobCreate,
@@ -56,12 +79,6 @@ func ResourceDataflowJob() *schema.Resource {
 		Timeouts: &schema.ResourceTimeout{
 			Update: schema.DefaultTimeout(10 * time.Minute),
 		},
-		CustomizeDiff: customdiff.All(
-			resourceDataflowJobTypeCustomizeDiff,
-		),
-		Importer: &schema.ResourceImporter{
-			State: schema.ImportStatePassthrough,
-		},
 		Schema: map[string]*schema.Schema{
 			"name": {
 				Type:     schema.TypeString,
@@ -169,7 +186,7 @@ func ResourceDataflowJob() *schema.Resource {
 			"subnetwork": {
 				Type:             schema.TypeString,
 				Optional:         true,
-				DiffSuppressFunc: compareSelfLinkOrResourceName,
+				DiffSuppressFunc: resourceDataflowJobSubnetworkDiffSuppress,
 				Description:      `The subnetwork to which VMs will be assigned. Should be of the form "regions/REGION/subnetworks/SUBNETWORK".`,
 			},
 
@@ -225,30 +242,6 @@ func ResourceDataflowJob() *schema.Resource {
 	}
 }
 
-func resourceDataflowJobTypeCustomizeDiff(_ context.Context, d *schema.ResourceDiff, meta interface{}) error {
-	// All non-virtual fields are ForceNew for batch jobs
-	if d.Get("type") == "JOB_TYPE_BATCH" {
-		resourceSchema := ResourceDataflowJob().Schema
-		for field := range resourceSchema {
-			if field == "on_delete" {
-				continue
-			}
-			// Labels map will likely have suppressed changes, so we check each key instead of the parent field
-			if field == "labels" {
-				if err := resourceDataflowJobIterateMapForceNew(field, d); err != nil {
-					return err
-				}
-			} else if d.HasChange(field) {
-				if err := d.ForceNew(field); err != nil {
-					return err
-				}
-			}
-		}
-	}
-
-	return nil
-}
-
 // return true if a job is in a terminal state, OR if a job is in a
 // terminating state and skipWait is true
 func shouldStopDataflowJobDeleteQuery(state string, skipWait bool) bool {
@@ -290,11 +283,18 @@ func resourceDataflowJobCreate(d *schema.ResourceData, meta interface{}) error {
 		Environment: &env,
 	}
 
+	id, err := replaceVars(d, config, "{{project}}/{{region}}/{{name}}")
+	if err != nil {
+		return fmt.Errorf("Error constructing id: %s", err)
+	}
+	d.SetId(id)
+
 	job, err := resourceDataflowJobCreateJob(config, project, region, userAgent, &request)
 	if err != nil {
+		d.SetId("")
 		return err
 	}
-	d.SetId(job.Id)
+	d.Set("job_id", job.Id)
 
 	return resourceDataflowJobRead(d, meta)
 }
@@ -316,10 +316,22 @@ func resourceDataflowJobRead(d *schema.ResourceData, meta interface{}) error {
 		return err
 	}
 
-	id := d.Id()
+	id := d.Get("job_id").(string)
 
-	job, err := resourceDataflowJobGetJob(config, project, region, userAgent, id)
-	if err != nil {
+	// If there's a job with the given name that is currently active, then get
+	// that job. Otherwise, fall back to getting the job using the job ID.
+	job, err := resourceDataflowJobGetActiveJobWithName(config, project, region, userAgent, d.Get("name").(string))
+	if errors.Is(err, activeJobNotFoundError) {
+		if id == "" {
+			log.Printf("[DEBUG] Dataflow job with empty job ID")
+			d.SetId("")
+			return nil
+		}
+		job, err = resourceDataflowJobGetJob(config, project, region, userAgent, id)
+		if err != nil {
+			return handleNotFoundError(err, d, fmt.Sprintf("Dataflow job %s", id))
+		}
+	} else if err != nil {
 		return handleNotFoundError(err, d, fmt.Sprintf("Dataflow job %s", id))
 	}
 
@@ -362,17 +374,22 @@ func resourceDataflowJobRead(d *schema.ResourceData, meta interface{}) error {
 	if err := d.Set("network", optionsMap["network"]); err != nil {
 		return fmt.Errorf("Error setting network: %s", err)
 	}
+	if err := d.Set("additional_experiments", optionsMap["experiments"]); err != nil {
+		return fmt.Errorf("Error setting additional_experiments: %s", err)
+	}
 	if err := d.Set("service_account_email", optionsMap["serviceAccountEmail"]); err != nil {
 		return fmt.Errorf("Error setting service_account_email: %s", err)
 	}
-
-	if ok := shouldStopDataflowJobDeleteQuery(job.CurrentState, d.Get("skip_wait_on_job_termination").(bool)); ok {
-		log.Printf("[DEBUG] Removing resource '%s' because it is in state %s.\n", job.Name, job.CurrentState)
-		d.SetId("")
-		return nil
+	if err := d.Set("enable_streaming_engine", optionsMap["enableStreamingEngine"]); err != nil {
+		return fmt.Errorf("Error setting enable_streaming_engine: %s", err)
+	}
+	if v, ok := optionsMap["subnetwork"]; ok && v != nil {
+		subnetwork, err := toSubnetworkSelfLink(v.(string), d, config)
+		if err != nil {
+			return err
+		}
+		d.Set("subnetwork", subnetwork)
 	}
-	d.SetId(job.Id)
-
 	return nil
 }
 
@@ -383,6 +400,10 @@ func resourceDataflowJobUpdateByReplacement(d *schema.ResourceData, meta interfa
 		return nil
 	}
 
+	if d.Get("type") == "JOB_TYPE_BATCH" {
+		return fmt.Errorf("Batch jobs cannot be updated.")
+	}
+
 	config := meta.(*Config)
 	userAgent, err := generateUserAgentString(d, config.userAgent)
 	if err != nil {
@@ -425,10 +446,10 @@ func resourceDataflowJobUpdateByReplacement(d *schema.ResourceData, meta interfa
 	}
 
 	if err := waitForDataflowJobToBeUpdated(d, config, response.Job.Id, userAgent, d.Timeout(schema.TimeoutUpdate)); err != nil {
-		return fmt.Errorf("Error updating job with job ID %q: %v", d.Id(), err)
+		return fmt.Errorf("Error updating job with job ID %q: %v", d.Get("job_id").(string), err)
 	}
 
-	d.SetId(response.Job.Id)
+	d.Set("job_id", response.Job.Id)
 
 	return resourceDataflowJobRead(d, meta)
 }
@@ -450,7 +471,12 @@ func resourceDataflowJobDelete(d *schema.ResourceData, meta interface{}) error {
 		return err
 	}
 
-	id := d.Id()
+	id := d.Get("job_id").(string)
+	if id == "" {
+		log.Printf("[DEBUG] Removing dataflow job with empty job ID")
+		d.SetId("")
+		return nil
+	}
 
 	requestedState, err := resourceDataflowJobMapRequestedState(d.Get("on_delete").(string))
 	if err != nil {
@@ -512,7 +538,7 @@ func resourceDataflowJobDelete(d *schema.ResourceData, meta interface{}) error {
 		d.SetId("")
 		return nil
 	}
-	return fmt.Errorf("Unable to cancel the dataflow job '%s' - final state was %q.", d.Id(), d.Get("state").(string))
+	return fmt.Errorf("Unable to cancel the dataflow job '%s' - final state was %q.", d.Get("job_id").(string), d.Get("state").(string))
 }
 
 func resourceDataflowJobMapRequestedState(policy string) (string, error) {
@@ -533,6 +559,34 @@ func resourceDataflowJobCreateJob(config *Config, project, region, userAgent str
 	return config.NewDataflowClient(userAgent).Projects.Locations.Templates.Create(project, region, request).Do()
 }
 
+// Gets active job, if there is any, with the given name in the given project
+// and the given region. An active job is any job whose state is one of
+// PENDING, RUNNING, QUEUED, DRAINING, CANCELLING, or STOPPED.
+// (source: https://cloud.google.com/dataflow/docs/reference/rest/v1b3/projects.jobs#Job.JobState)
+func resourceDataflowJobGetActiveJobWithName(config *Config, project, region, userAgent, name string) (*dataflow.Job, error) {
+	pageToken := ""
+	for ok := true; ok; ok = pageToken != "" {
+		resp, err := config.NewDataflowClient(userAgent).Projects.Jobs.Aggregated(project).
+			Filter("ACTIVE").
+			View("JOB_VIEW_SUMMARY").
+			PageSize(25).
+			PageToken(pageToken).
+			Do()
+		if err != nil {
+			return nil, fmt.Errorf("error listing active jobs in project %v: %v", project, err)
+		}
+
+		for _, j := range resp.Jobs {
+			if j.Name == name && j.Location == region {
+				return resourceDataflowJobGetJob(config, project, j.Location, userAgent, j.Id)
+			}
+		}
+
+		pageToken = resp.NextPageToken
+	}
+	return nil, activeJobNotFoundError
+}
+
 func resourceDataflowJobGetJob(config *Config, project, region, userAgent string, id string) (*dataflow.Job, error) {
 	if region == "" {
 		return config.NewDataflowClient(userAgent).Projects.Jobs.Get(project, id).View("JOB_VIEW_ALL").Do()
@@ -557,6 +611,11 @@ func resourceDataflowJobLaunchTemplate(config *Config, project, region, userAgen
 func resourceDataflowJobSetupEnv(d *schema.ResourceData, config *Config) (dataflow.RuntimeEnvironment, error) {
 	zone, _ := getZone(d, config)
 
+	subnetwork, err := toSubnetworkSelfLink(d.Get("subnetwork").(string), d, config)
+	if err != nil {
+		return dataflow.RuntimeEnvironment{}, err
+	}
+
 	labels := expandStringMap(d, "labels")
 
 	additionalExperiments := convertStringSet(d.Get("additional_experiments").(*schema.Set))
@@ -565,7 +624,7 @@ func resourceDataflowJobSetupEnv(d *schema.ResourceData, config *Config) (datafl
 		MaxWorkers:            int64(d.Get("max_workers").(int)),
 		Network:               d.Get("network").(string),
 		ServiceAccountEmail:   d.Get("service_account_email").(string),
-		Subnetwork:            d.Get("subnetwork").(string),
+		Subnetwork:            subnetwork,
 		TempLocation:          d.Get("temp_gcs_location").(string),
 		MachineType:           d.Get("machine_type").(string),
 		KmsKeyName:            d.Get("kms_key_name").(string),
@@ -656,3 +715,29 @@ func waitForDataflowJobToBeUpdated(d *schema.ResourceData, config *Config, repla
 		}
 	})
 }
+
+// toSubnetworkSelfLink converts the given string to a subnetwork self-link of the format:
+//   https://www.googleapis.com/compute/v1/projects/{project}/regions/{region}/subnetworks/{subnetwork_name}
+// The following input formats are supported:
+// - https://www.googleapis.com/compute/ANY_VERSION/projects/{project}/regions/{region}/subnetworks/{subnetwork_name}
+// - projects/{project}/regions/{region}/subnetworks/{subnetwork_name}
+// - regions/{region}/subnetworks/{subnetwork_name}
+// - {subnetwork_name}
+// - "" (empty string). toSubnetworkSelfLink will return an empty string in this case.
+func toSubnetworkSelfLink(subnetwork string, d *schema.ResourceData, config *Config) (string, error) {
+	fv, err := ParseSubnetworkFieldValue(subnetwork, d, config)
+	if err != nil {
+		return "", err
+	}
+	if fv.RelativeLink() == "" {
+		return "", nil
+	}
+	// Dataflow only respects the legacy compute base path with domain www.googleapis.com, not
+	// compute.googleapis.com
+	legacyComputeBasePath := "https://www.googleapis.com/compute/beta/"
+	url, err := replaceVars(d, config, legacyComputeBasePath+fv.RelativeLink())
+	if err != nil {
+		return "", err
+	}
+	return ConvertSelfLinkToV1(url), nil
+}
